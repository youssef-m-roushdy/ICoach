import pandas as pd
import requests
import os
import shutil

# --- Configuration ---
CSV_FILE = "body_parts_final-edit.csv" Â # Path to your CSV file
IMAGE_COLUMN = "gif_link" Â  Â # Name of the column containing GIF/image URLs
OUTPUT_FOLDER = "local_gifs" Â  Â # Name of the folder to save images

# Ensure the output folder exists
if not os.path.exists(OUTPUT_FOLDER):
Â  Â  os.makedirs(OUTPUT_FOLDER)

# Read the CSV file
try:
Â  Â  df = pd.read_csv(CSV_FILE)
Â  Â  print(f"âœ… File successfully read: {CSV_FILE}")
except:
Â  Â  print("âŒ File not found, please check the name")
Â  Â  exit()

# Function to download the image
def download_image(url, index):
Â  Â  try:
Â  Â  Â  Â  # Attempt download as a browser (to bypass server restrictions)
Â  Â  Â  Â  headers = {'User-Agent': 'Mozilla/5.0'}
Â  Â  Â  Â  response = requests.get(url, headers=headers, stream=True, timeout=10)
Â  Â  Â  Â  
Â  Â  Â  Â  if response.status_code == 200:
Â  Â  Â  Â  Â  Â  # Extract file extension (gif, png, etc.)
Â  Â  Â  Â  Â  Â  ext = url.split('.')[-1].split('?')[0]
Â  Â  Â  Â  Â  Â  if len(ext) > 4: ext = "gif" # Default to 'gif' if extension is unusual
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  filename = f"exercise_{index}.{ext}"
Â  Â  Â  Â  Â  Â  file_path = os.path.join(OUTPUT_FOLDER, filename)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  with open(file_path, 'wb') as f:
Â  Â  Â  Â  Â  Â  Â  Â  response.raw.decode_content = True
Â  Â  Â  Â  Â  Â  Â  Â  shutil.copyfileobj(response.raw, f)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  return file_path # Return the new local path
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  print(f"âš ï¸ Failed to download link (Code {response.status_code}): {url}")
Â  Â  Â  Â  Â  Â  return None
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error processing link: {url} - {e}")
Â  Â  Â  Â  return None

# The Main Loop
print("â³ Downloading images... This may take a moment...")

new_paths = []
for index, row in df.iterrows():
Â  Â  url = row[IMAGE_COLUMN]
Â  Â  
Â  Â  # If the cell is not empty and contains a URL
Â  Â  if isinstance(url, str) and url.startswith("http"):
Â  Â  Â  Â  local_path = download_image(url, index)
Â  Â  Â  Â  if local_path:
Â  Â  Â  Â  Â  Â  new_paths.append(local_path) # Image saved, use the new path
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  new_paths.append(None) # Download failed, set path to None
Â  Â  else:
Â  Â  Â  Â  new_paths.append(url) # If it's not a URL, keep original value

# Update the DataFrame
df['local_image_path'] = new_paths # New column for local paths

# Save the clean, new CSV file
df.to_csv("exercises_fixed.csv", index=False)
print("\nğŸ‰ Success! Images downloaded and new file 'exercises_fixed.csv' created.")
print("Now use the new column 'local_image_path' in Streamlit.")